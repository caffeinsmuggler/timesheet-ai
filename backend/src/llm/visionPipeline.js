// src/llm/visionPipeline.js

const vision = require('@google-cloud/vision');
const { GoogleGenerativeAI } = require('@google/generative-ai');
const fs = require('fs');
const path = require('path');
require('dotenv').config();
const { extractKoreanNamesFromTokens } = require('./nameExtractor');
const { matchAgainstEmployees } = require('./matcher');

function postFixNames(visionParsed) {
 return visionParsed.map(e => {
  const names = new Set(e.extracted_names || []);
  // 2ê¸€ìë§Œ ìˆìœ¼ë©´ ì„±ì”¨/ë§ë¯¸ ë³´ê°• ì¬ì‹œë„
  if (names.size===1) {
   const only = [...names][0];
   if (only.length===2 && (e.tokens?.length)) {
    const repaired = extractKoreanNamesFromTokens(e.tokens, e.text);
    repaired.forEach(n => names.add(n));
   }
  }
  return { ...e, extracted_names: [...names] };
 });
}

// Vision API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
const visionClient = new vision.ImageAnnotatorClient({
 keyFilename: process.env.VISION_CREDENTIALS_PATH
});

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);

// ì§ì› ë°ì´í„° ë¡œë“œ
function loadEmployeeData() {
 try {
  const dataPath = path.join(__dirname, '../../data/employees.json');
console.log('ğŸ“‚ Loading employee data from:', dataPath);
const info = fs.readFileSync(dataPath, 'utf-8');
  return JSON.parse(info);
 } catch (e) {
  console.warn('âš ï¸ Employee data not found');
  return { day_shift: [], night_shift: [], idiomatic_expressions: {} };
 }
}

// STEP 1: Vision APIë¡œ í…ìŠ¤íŠ¸ + ì¢Œí‘œ ì¶”ì¶œ
async function visionExtract(imageBase64) {
 console.log('ğŸ” Vision API: Extracting text with coordinatesâ€¦');

 const imageBuffer = Buffer.from(imageBase64, 'base64');

 const [result] = await visionClient.documentTextDetection({
  image: { content: imageBuffer }
 });

 const fullTextAnnotation = result.fullTextAnnotation;

 if (!fullTextAnnotation) {
  console.warn('âš ï¸ No text detected');
  return [];
 }

 // í˜ì´ì§€ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
 const pages = fullTextAnnotation.pages || [];
 const extractedEntries = [];

 for (const page of pages) {
  for (const block of page.blocks) {
   for (const paragraph of block.paragraphs) {
    const words = paragraph.words.map(word => {
     const text = word.symbols.map(s => s.text).join('');
     const boundingBox = word.boundingBox.vertices;
     return { text, boundingBox };
    });

    extractedEntries.push({
     text: words.map(w => w.text).join(' '),
     tokens: words, // â† í† í° ë³´ì¡´
     boundingBox: paragraph.boundingBox.vertices
    });
   }
  }
 }

 console.log(`âœ“ Vision extracted ${extractedEntries.length} text blocks`);
 return extractedEntries;
}

// í—¤ë” ì œì™¸ í•¨ìˆ˜
function filterHeaders(entries) {
 const headerKeywords = ['ë¹„ê³ ', 'ìš”ì¼', 'ë³´ì•ˆì¼ê·¼', 'ë¶€()', 'ë…„', 'ì›”', 'ì¼'];

 return entries.filter(entry => {
  const text = entry.text.trim();

  // Row 1~2ëŠ” ë¬´ì¡°ê±´ ì œì™¸
  if (entry.boundingBox[0].y < 150) return false;

  // í—¤ë” í‚¤ì›Œë“œ í¬í•¨ ì‹œ ì œì™¸
  for (const keyword of headerKeywords) {
   if (text.includes(keyword)) return false;
  }

  return true;
 });
}

// X ì¢Œí‘œë¡œ ì—´ ë²”ìœ„ í• ë‹¹
function assignColumnByX(entries) {
 return entries.map(entry => {
  const x = entry.boundingBox[0].x;
  let column;

  if (x < 200) column = 1;    // íœ´ê°€ ìœ í˜• ë¼ë²¨
  else if (x < 400) column = 2;  // ë³´ì•ˆì¼ê·¼ 1~6
  else if (x < 600) column = 3;  // ë³´ì•ˆì¼ê·¼ 7~12
  else if (x < 800) column = 4;  // ì•¼ê·¼ 1ë¶€
  else if (x < 1000) column = 5; // ì•¼ê·¼ 2ë¶€
  else if (x < 1200) column = 6; // ì•¼ê·¼ 3ë¶€
  else column = 7;        // ì•¼ê·¼ 4ë¶€

  return { ...entry, column };
 });
}

// íœ´ê°€ ìœ í˜• ì„¹ì…˜ ë¶„ë¦¬
function parseSections(entries) {
 const leaveTypes = ['ì—°ê°€', 'ì¡°í‡´', 'ë³‘ê°€', 'íŠ¹íœ´', 'êµìœ¡'];
 const sections = [];
 let currentSection = null;

 entries.forEach(entry => {
  if (entry.column === 1) {
   // íœ´ê°€ ìœ í˜• ë¼ë²¨ ë°œê²¬ ì‹œ ìƒˆ ì„¹ì…˜ ì‹œì‘
   for (const type of leaveTypes) {
    if (entry.text.includes(type)) {
     if (currentSection) sections.push(currentSection);
     currentSection = { type, names: [] };
     return;
    }
   }
  }

  // Column 2 ì´ìƒë§Œ ì´ë¦„ìœ¼ë¡œ ê°„ì£¼
  if (entry.column >= 2 && currentSection) {
   currentSection.names.push(entry);
  }
 });

 if (currentSection) sections.push(currentSection);

 return sections;
}

function expandEntriesByNames(visionParsed) {
 const out = [];
 for (const e of visionParsed) {
  const names = e.extracted_names || [];
  if (names.length === 0) {
   // ì´ë¦„ì´ ì—†ìœ¼ë©´ ìŠ¤í‚µ(ë˜ëŠ” ê·¸ëŒ€ë¡œ ë‚¨ê²¨ì„œ 'ë¯¸ì‹ë³„'ë¡œ í‘œê¸°)
   continue;
  }
  for (const n of names) {
   out.push({
    row: e.row,
    column: e.column,
    raw_name: n,
    leaveType: e.leaveType,
    boundingBox: e.boundingBox,
    tokens: e.tokens || []
   });
  }
 }
 return out;
}

// í…œí”Œë¦¿ ê¸°ë°˜ í‘œ íŒŒì‹± (ê·¼íƒœë¶€ ì „ìš©)
function parseTimesheetTable(visionRaw) {
 console.log('ğŸ“‹ Parsing timesheet table with templateâ€¦');

 // Step 1: í—¤ë” ì œê±°
 const filtered = filterHeaders(visionRaw);
 console.log(`âœ“ Filtered ${visionRaw.length - filtered.length} header entries`);

// Step 1.5: í† í° ê¸°ë°˜ ì´ë¦„ ì¶”ì¶œ
 console.log('ğŸ” Step 1.5: Extracting Korean names (token-level)â€¦');
 const withNames = filtered.map(entry => {
  const names = extractKoreanNamesFromTokens(entry.tokens || [], entry.text || '');
  return { ...entry, extracted_names: names };
 });
 // Step 2: ì—´ ë²”ìœ„ í• ë‹¹
 const withColumns = assignColumnByX(withNames);

 // Step 3: ì„¹ì…˜ íŒŒì‹±
 const sections = parseSections(withColumns);
 console.log(`âœ“ Parsed ${sections.length} leave type sections`);

 // Step 4: í‰íƒ„í™” (ì„¹ì…˜ë³„ ì´ë¦„ ì¶”ì¶œ)
 const result = [];
 sections.forEach(section => {
  section.names.forEach((entry, idx) => {
   result.push({
    row: idx + 1,
    column: entry.column,
    text: entry.text,
    extracted_names: entry.extracted_names || [],
    leaveType: section.type,
    boundingBox: entry.boundingBox,
    tokens: entry.tokens || []
   });
  });
 });

 return result;
}

// STEP 2: Proë¡œ í›„ë³´ ìƒì„± (geminiPipelineê³¼ ë™ì¼)
async function proRefineWithCandidates(visionResult, employeeData) {
 const model = genAI.getGenerativeModel({
 model: 'gemini-2.5-pro'
 });

 const dayList = employeeData.day_shift.join(', ');
 const nightList = employeeData.night_shift.join(', ');

 const prompt = `You are an expert name matcher for Korean employee timesheets.

**DAY_SHIFT (columns 2-3):** ${dayList}
**NIGHT_SHIFT (columns 4-7):** ${nightList}

**Vision API extraction result:**
${JSON.stringify(visionResult, null, 2)}

For EACH entry, generate:
1. Top 3 candidate names from the appropriate shift list (based on column)
2. Confidence score (0-100) for each candidate
3. Step-by-step reasoning explaining your choice

**Output schema:**
{
 "entries": [
  {
   "column": 2,
   "row": 1,
   "raw_name": "ê¹€ì² ìˆ˜",
   "candidates": [
    { "name": "ê¹€ì² ìˆ˜", "confidence": 95 },
    { "name": "ê¹€ì² í˜¸", "confidence": 4 },
    { "name": "ê¹€ì² ìˆœ", "confidence": 1 }
   ],
   "selected": "ê¹€ì² ìˆ˜",
   "reasoning": [
    "Vision OCR: 'ê¹€ì² ìˆ˜' (clear text)",
    "Column 2 â†’ DAY_SHIFT list",
    "Exact match found: ê¹€ì² ìˆ˜",
    "Confidence: 95%"
   ],
   "leave_type": "ì—°ê°€",
"attendance_type": "Present",
   "leave_early_minutes": 0
  }
 ]
}

**Critical:**
- Explain your reasoning step by step
- Calculate Levenshtein distance accurately
- Sum confidence scores per entry to 100%
- Return ONLY valid JSON`;

 const result = await model.generateContent([prompt]);
 const response = await result.response;
 const text = response.text();

 let jsonText = text.trim();
 if (jsonText.startsWith('```')) {
 jsonText = jsonText.replace(/^```(?:json)?\n?/, '').replace(/\n?```$/, '');
 }

 return JSON.parse(jsonText);
}

// ì „ì²´ íŒŒì´í”„ë¼ì¸
async function processWithVisionPipeline(imageBase64, mimeType = 'image/png') {
 console.log('ğŸ”„ Stage 1: Vision API extractionâ€¦');
 const visionRaw = await visionExtract(imageBase64);

 console.log('ğŸ”„ Stage 1.5: Template-based table parsingâ€¦');
 const parsed0 = parseTimesheetTable(visionRaw);
 console.log(`âœ“ Parsed ${parsed0.length} blocks`);

 // 1. í† í° ê¸°ë°˜ ì´ë¦„ ì¶”ì¶œ ì¶”ê°€
 console.log('ğŸ” Step 1.6: Token-level Korean name extractionâ€¦');
 const withNames = parsed0.map(entry => {
  const names = extractKoreanNamesFromTokens(entry.tokens || [], entry.text || '');
  return { ...entry, extracted_names: names };
 });

 // 2. ì´ë¦„ ë³´ì •(ì„±ì”¨/ë§ë¯¸ ë³´ê°•)
 console.log('ğŸ› ï¸ Step 1.7: Name post-fix (surname/ending repair)â€¦');
 const withNamesFixed = postFixNames(withNames);

 // 3. ì—¬ëŸ¬ ì´ë¦„ í™•ì¥
 console.log('ğŸ§© Step 1.8: Expand entries by namesâ€¦');
 const expanded = expandEntriesByNames(withNamesFixed);
 console.log(`âœ“ Expanded to ${expanded.length} name entries`);

 // 4. ë¡œì»¬ ë§¤ì¹­(LLM ë¯¸ì‚¬ìš©)
 console.log('ğŸ¤ Stage 2: Employee matching (local, jamo-distance)â€¦');
 const employeeData = loadEmployeeData();
 const refinedEntries = expanded.map(e => {
  const { candidates, selected, reasoning } = matchAgainstEmployees(e, employeeData);
  return {
   column: e.column,
   row: e.row,
   raw_name: e.raw_name,
   candidates,
   selected,
   reasoning,
   leave_type: e.leaveType,
   attendance_type: 'Unknown',
   leave_early_minutes: 0
  };
 });

 return {
  vision_raw: visionRaw,
  // ë³´ì •ëœ ì—”íŠ¸ë¦¬ë¥¼ vision_parsedë¡œ ë°˜í™˜(í”„ë¡ íŠ¸ì—ì„œ í™•ì¸í•˜ê¸° ì‰¬ì›€)
  vision_parsed: withNamesFixed,
  refined: { entries: refinedEntries },
   details: {
    day_shift_count: employeeData.day_shift.length,
    night_shift_count: employeeData.night_shift.length,
    processed_at: new Date().toISOString(),
    warped_image_path: null,   // ì¶”ê°€ (ê°’ ë¯¸ì •ì‹œ nullë¡œ ì•ˆì „í•˜ê²Œ ì„¤ì •)
    warped_width: null,        // ì¶”ê°€ (ê°’ ë¯¸ì •ì‹œ nullë¡œ ì•ˆì „í•˜ê²Œ ì„¤ì •)
    warped_height: null        // ì¶”ê°€ (ê°’ ë¯¸ì •ì‹œ nullë¡œ ì•ˆì „í•˜ê²Œ ì„¤ì •)
   }
 };
}

module.exports = {
 processWithVisionPipeline,
 visionExtract,
 loadEmployeeData
};